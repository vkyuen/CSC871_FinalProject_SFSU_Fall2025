{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472bd647",
   "metadata": {},
   "source": [
    "# Creating and training models\n",
    "This file/notebook will create and train different models to see how different models will act.  Once the model has been trained, it will save the models to a folder for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e712c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_module import get_data_loaders\n",
    "import os\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fae29",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e19adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a351468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530b2cf",
   "metadata": {},
   "source": [
    "## Loading data loaders\n",
    "Putting the loaders in a dictionary.  Since this file focuses on the models, I really only need the training and validation sets, but since all three loaders are given, it wouldn't hurt to add it to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4e3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5216 images from chest_xray/train\n",
      "Loaded 782 images from chest_xray/val_new\n",
      "Loaded 624 images from chest_xray/test\n",
      "\n",
      "✅ Data loaders created!\n",
      "   Train: 5216 images\n",
      "   Val:   782 images\n",
      "   Test:  624 images\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders(batch_size=32)\n",
    "dataloaders = {\"TRAIN\": train_loader, \"VAL\": val_loader, \"TEST\": test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec03560",
   "metadata": {},
   "source": [
    "## Define a training function\n",
    "Followed a tutorial that trains and validates the model at each epoch. With each training, the model, optimizer, criterion, number of epochs and the early stopping critera can be set. \n",
    "\n",
    "At the end of each epoch, the statistics is printed to the console, before checking to see if the stopping critera has been met, and if the current model the is being tested is the best model.  If it is, then it is saved to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4554e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, num_epochs=50, early_stopping=None):\n",
    "    model.train()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in [\"TRAIN\", \"VAL\"]:\n",
    "            if phase == \"TRAIN\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == \"TRAIN\"):\n",
    "                    outputs = model(inputs)  # Shape: (batch_size, 1), dtype: float\n",
    "                    outputs = outputs.squeeze(1)  # Shape: (batch_size,), dtype: float\n",
    "                    loss = criterion(outputs, labels.float())  # ✅ Convert labels to float\n",
    "                    prediction = torch.sigmoid(outputs).round().long()  # For accuracy calculation\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                if phase == \"TRAIN\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_accuracy += torch.sum(prediction == labels)\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_accuracy.double() / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Early stopping\n",
    "            if phase == \"VAL\":\n",
    "                early_stopping(epoch_loss, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "\n",
    "            # Save the best model\n",
    "            if phase == \"VAL\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad472a0f",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "This method checks to make sure the training stops in time to prevent overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546aec0",
   "metadata": {},
   "source": [
    "## Generate the different models\n",
    "Create instances of the different model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e41eac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f5ddd",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d55bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 56 * 56, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)  # Binary classification\n",
    "    )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1167d36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "----------\n",
      "TRAIN Loss: 82.3640 Acc: 0.7421\n",
      "VAL Loss: 81.0791 Acc: 0.7430\n",
      "Epoch 2/30\n",
      "----------\n",
      "TRAIN Loss: 82.3645 Acc: 0.7427\n",
      "VAL Loss: 81.0791 Acc: 0.7430\n",
      "Epoch 3/30\n",
      "----------\n",
      "TRAIN Loss: 82.3666 Acc: 0.7408\n",
      "VAL Loss: 81.0791 Acc: 0.7430\n",
      "Epoch 4/30\n",
      "----------\n",
      "TRAIN Loss: 82.3684 Acc: 0.7410\n",
      "VAL Loss: 81.0791 Acc: 0.7430\n",
      "Epoch 5/30\n",
      "----------\n",
      "TRAIN Loss: 82.3636 Acc: 0.7425\n",
      "VAL Loss: 81.0791 Acc: 0.7430\n",
      "Epoch 6/30\n",
      "----------\n",
      "TRAIN Loss: 82.3746 Acc: 0.7433\n",
      "VAL Loss: 81.0791 Acc: 0.7430\n",
      "Epoch 7/30\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "modelCNN = cnn_model().to(device)\n",
    "optimizerCNN = optim.SGD(cnn_model().parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "early_stopCNN = EarlyStopping(patience=7, delta=0.01)\n",
    "\n",
    "\n",
    "trainedCNN = train_model(modelCNN, optimizerCNN, criterion, num_epochs=30, early_stopping=early_stopCNN)\n",
    "pathcnn = os.path.join(\"saved_models\", \"cnn_model.pth\")\n",
    "torch.save(trainedCNN.state_dict(), pathcnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fd207",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet18Wts = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = modelResNet18Wts.fc.in_features\n",
    "\n",
    "for param in modelResNet18Wts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet18Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet18Wts = optim.SGD(modelResNet18Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet18Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "trainedResNet18Wts = train_model(modelResNet18Wts, optimizerResNet18Wts, criterion, num_epochs=30, early_stopping=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "324eca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"saved_models\", \"resnet18_weights.pth\")\n",
    "torch.save(trainedResNet18Wts.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63be28",
   "metadata": {},
   "source": [
    "### ResNet 18 without default weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24233d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet18 = models.resnet18()\n",
    "num_ftrs = modelResNet18.fc.in_features\n",
    "\n",
    "for param in modelResNet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet18.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet18 = optim.SGD(modelResNet18.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet18 = EarlyStopping(patience=7, delta=0.01)\n",
    "trainedResNet18 = train_model(modelResNet18, optimizerResNet18, criterion, num_epochs=30, early_stopping=early_stopResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef7b80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathResNet18 = os.path.join(\"saved_models\", \"resnet18.pth\")\n",
    "torch.save(trainedResNet18.state_dict(), pathResNet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09206fb",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "857c2b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /Users/vky/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "modelResNet50Wts = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = modelResNet50Wts.fc.in_features\n",
    "\n",
    "for param in modelResNet50Wts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet50Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet50Wts = optim.SGD(modelResNet50Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet50Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "trainedResNet50Wts = train_model(modelResNet50Wts, optimizerResNet50Wts, criterion, num_epochs=30, early_stopping=early_stopResNet50Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "03426888",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathResNet50Wts = os.path.join(\"saved_models\", \"resnet50_weights.pth\")\n",
    "torch.save(trainedResNet50Wts.state_dict(), pathResNet50Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d090d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet50 = models.resnet50()\n",
    "num_ftrs = modelResNet50.fc.in_features\n",
    "\n",
    "for param in modelResNet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet50.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet50 = optim.SGD(modelResNet50.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet50 = EarlyStopping(patience=7, delta=0.01)\n",
    "trainedResNet50 = train_model(modelResNet50, optimizerResNet50, criterion, num_epochs=30, early_stopping=early_stopResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dcb78e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathresnet50 = os.path.join(\"saved_models\", \"resnet50.pth\")\n",
    "torch.save(trainedResNet50.state_dict(), pathresnet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ab842",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e368cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG16Wts = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "\n",
    "for param in modelVGG16Wts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = modelVGG16Wts.classifier[6].in_features\n",
    "features = list(modelVGG16Wts.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "modelVGG16Wts.classifier = nn.Sequential(*features)\n",
    "\n",
    "optimizerVGG16Wts = optim.SGD(modelVGG16Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopVGG16Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "trainedVGG16Wts = train_model(modelVGG16Wts, optimizerVGG16Wts, criterion, num_epochs=30, early_stopping=early_stopVGG16Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4f12821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathVGG16Wts = os.path.join(\"saved_models\", \"vgg16_weights.pth\")\n",
    "torch.save(trainedVGG16Wts.state_dict(), pathVGG16Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG16 = models.vgg16()\n",
    "\n",
    "for param in modelVGG16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = modelVGG16.classifier[6].in_features\n",
    "features = list(modelVGG16.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "modelVGG16.classifier = nn.Sequential(*features)\n",
    "\n",
    "optimizerVGG16 = optim.SGD(modelVGG16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopVGG16 = EarlyStopping(patience=7, delta=0.01)\n",
    "trainedVGG16 = train_model(modelVGG16, optimizerVGG16, criterion, num_epochs=30, early_stopping=early_stopVGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2aa05592",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathVGG16Wts = os.path.join(\"saved_models\", \"vgg16_weights.pth\")\n",
    "torch.save(trainedVGG16Wts.state_dict(), pathVGG16Wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abd90a",
   "metadata": {},
   "source": [
    "## Optimizers and loss functions\n",
    "Potentially different for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5c59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
