{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472bd647",
   "metadata": {},
   "source": [
    "# Creating and training models\n",
    "This file/notebook will create and train different models to see how different models will act.  Once the model has been trained, it will save the models to a folder for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e712c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_module import get_data_loaders\n",
    "import os\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fae29",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e19adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530b2cf",
   "metadata": {},
   "source": [
    "## Loading data loaders\n",
    "Putting the loaders in a dictionary.  Since this file focuses on the models, I really only need the training and validation sets, but since all three loaders are given, it wouldn't hurt to add it to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4e3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5216 images from chest_xray/train\n",
      "Loaded 782 images from chest_xray/val_new\n",
      "Loaded 624 images from chest_xray/test\n",
      "\n",
      "✅ Data loaders created!\n",
      "   Train: 5216 images\n",
      "   Val:   782 images\n",
      "   Test:  624 images\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders(batch_size=32)\n",
    "dataloaders = {\"TRAIN\": train_loader, \"VAL\": val_loader, \"TEST\": test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec03560",
   "metadata": {},
   "source": [
    "## Define a training function\n",
    "Followed a tutorial that trains and validates the model at each epoch. With each training, the model, optimizer, criterion, number of epochs and the early stopping critera can be set. \n",
    "\n",
    "At the end of each epoch, the statistics is printed to the console, before checking to see if the stopping critera has been met, and if the current model the is being tested is the best model.  If it is, then it is saved to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4554e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, num_epochs=50, early_stopping=None):\n",
    "    model.train()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        \n",
    "        for phase in [\"TRAIN\", \"VAL\"]:\n",
    "            if phase == \"TRAIN\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            # running_accuracy = 0.0\n",
    "            running_correct = 0\n",
    "            running_total = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == \"TRAIN\"):\n",
    "                    outputs = model(inputs)  # Shape: (batch_size, 1), dtype: float\n",
    "                    outputs = outputs.squeeze(1)  # Shape: (batch_size,), dtype: float\n",
    "                    loss = criterion(outputs, labels.float())  # ✅ Convert labels to float\n",
    "                    prediction = torch.sigmoid(outputs).round().long()  # For accuracy calculation\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                if phase == \"TRAIN\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # running_accuracy += torch.sum(prediction == labels)\n",
    "                running_total += labels.size(0)\n",
    "                running_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            # epoch_acc = running_accuracy.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = (running_correct/running_total) * 100\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.2f} Acc: {epoch_acc:.2f}')\n",
    "\n",
    "            # Early stopping\n",
    "            if phase == \"VAL\":\n",
    "                early_stopping(epoch_loss, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "\n",
    "            # Save the best model\n",
    "            if phase == \"VAL\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.2f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad472a0f",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "This method checks to make sure the training stops in time to prevent overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ba206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546aec0",
   "metadata": {},
   "source": [
    "## Generate the different models\n",
    "Create instances of the different model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e41eac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fbe42",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 56 * 56, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)  # Binary classification\n",
    "    )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b80a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN = cnn_model().to(device)\n",
    "optimizerCNN = optim.SGD(cnn_model().parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopCNN = EarlyStopping(patience=7, delta=0.01)\n",
    "modelCNN = modelCNN.to(device)\n",
    "\n",
    "trainedCNN = train_model(modelCNN, optimizerCNN, criterion, num_epochs=30, early_stopping=early_stopCNN)\n",
    "pathcnn = os.path.join(\"saved_models\", \"cnn_model.pth\")\n",
    "torch.save(trainedCNN.state_dict(), pathcnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe729f",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d01a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet18Wts = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = modelResNet18Wts.fc.in_features\n",
    "\n",
    "for param in modelResNet18Wts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet18Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet18Wts = optim.SGD(modelResNet18Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet18Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet18Wts = modelResNet18Wts.to(device)\n",
    "\n",
    "trainedResNet18Wts = train_model(modelResNet18Wts, optimizerResNet18Wts, criterion, num_epochs=30, early_stopping=early_stop)\n",
    "\n",
    "path = os.path.join(\"saved_models\", \"resnet18_weights.pth\")\n",
    "torch.save(trainedResNet18Wts.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet18 = models.resnet18()\n",
    "num_ftrs = modelResNet18.fc.in_features\n",
    "\n",
    "for param in modelResNet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet18.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet18 = optim.SGD(modelResNet18.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet18 = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet18 = modelResNet18.to(device)\n",
    "\n",
    "trainedResNet18 = train_model(modelResNet18, optimizerResNet18, criterion, num_epochs=30, early_stopping=early_stopResNet18)\n",
    "\n",
    "pathResNet18 = os.path.join(\"saved_models\", \"resnet18.pth\")\n",
    "torch.save(trainedResNet18.state_dict(), pathResNet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383843c9",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0172662",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet50Wts = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = modelResNet50Wts.fc.in_features\n",
    "\n",
    "for param in modelResNet50Wts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet50Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet50Wts = optim.SGD(modelResNet50Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet50Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet50Wts = modelResNet50Wts.to(device)\n",
    "\n",
    "trainedResNet50Wts = train_model(modelResNet50Wts, optimizerResNet50Wts, criterion, num_epochs=30, early_stopping=early_stopResNet50Wts)\n",
    "\n",
    "pathResNet50Wts = os.path.join(\"saved_models\", \"resnet50_weights.pth\")\n",
    "torch.save(trainedResNet50Wts.state_dict(), pathResNet50Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet50 = models.resnet50()\n",
    "num_ftrs = modelResNet50.fc.in_features\n",
    "\n",
    "for param in modelResNet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelResNet50.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "optimizerResNet50 = optim.SGD(modelResNet50.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet50 = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet50 = modelResNet50.to(device)\n",
    "\n",
    "trainedResNet50 = train_model(modelResNet50, optimizerResNet50, criterion, num_epochs=30, early_stopping=early_stopResNet50)\n",
    "\n",
    "pathresnet50 = os.path.join(\"saved_models\", \"resnet50.pth\")\n",
    "torch.save(trainedResNet50.state_dict(), pathresnet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5807f",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f26f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG16Wts = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "\n",
    "for param in modelVGG16Wts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = modelVGG16Wts.classifier[6].in_features\n",
    "features = list(modelVGG16Wts.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "modelVGG16Wts.classifier = nn.Sequential(*features)\n",
    "\n",
    "optimizerVGG16Wts = optim.SGD(modelVGG16Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopVGG16Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelVGG16Wts = modelVGG16Wts.to(device)\n",
    "\n",
    "trainedVGG16Wts = train_model(modelVGG16Wts, optimizerVGG16Wts, criterion, num_epochs=30, early_stopping=early_stopVGG16Wts)\n",
    "\n",
    "pathVGG16Wts = os.path.join(\"saved_models\", \"vgg16_weights.pth\")\n",
    "torch.save(trainedVGG16Wts.state_dict(), pathVGG16Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG16 = models.vgg16()\n",
    "\n",
    "for param in modelVGG16.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = modelVGG16.classifier[6].in_features\n",
    "features = list(modelVGG16.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "modelVGG16.classifier = nn.Sequential(*features)\n",
    "\n",
    "optimizerVGG16 = optim.SGD(modelVGG16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopVGG16 = EarlyStopping(patience=7, delta=0.01)\n",
    "modelVGG16 = modelVGG16.to(device)\n",
    "\n",
    "trainedVGG16 = train_model(modelVGG16, optimizerVGG16, criterion, num_epochs=30, early_stopping=early_stopVGG16)\n",
    "\n",
    "pathVGG16 = os.path.join(\"saved_models\", \"vgg16.pth\")\n",
    "torch.save(trainedVGG16.state_dict(), pathVGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd0aa4d",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be4f2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDensenetWts = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "num_ftrs = modelDensenetWts.classifier.in_features\n",
    "\n",
    "for param in modelDensenetWts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelDensenetWts.classifier = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "optimizerDensenetWts = optim.Adam(modelDensenetWts.classifier.parameters(), lr=0.001)\n",
    "\n",
    "early_stopDensenetWts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelDensenetWts = modelDensenetWts.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3240a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/50\n",
      "TRAIN Loss: 0.02 Acc: 92.39\n",
      "VAL Loss: 0.00 Acc: 97.31\n",
      "----------\n",
      "Epoch 2/50\n",
      "TRAIN Loss: 0.01 Acc: 91.70\n",
      "VAL Loss: 0.00 Acc: 91.82\n",
      "----------\n",
      "Epoch 3/50\n",
      "TRAIN Loss: 0.01 Acc: 90.45\n",
      "VAL Loss: 0.00 Acc: 91.43\n",
      "----------\n",
      "Epoch 4/50\n",
      "TRAIN Loss: 0.01 Acc: 93.50\n",
      "VAL Loss: 0.00 Acc: 91.43\n",
      "----------\n",
      "Epoch 5/50\n",
      "TRAIN Loss: 0.01 Acc: 91.66\n",
      "VAL Loss: 0.01 Acc: 91.94\n",
      "----------\n",
      "Epoch 6/50\n",
      "TRAIN Loss: 0.02 Acc: 87.98\n",
      "VAL Loss: 0.01 Acc: 83.12\n",
      "----------\n",
      "Epoch 7/50\n",
      "TRAIN Loss: 0.02 Acc: 90.09\n",
      "VAL Loss: 0.00 Acc: 95.40\n",
      "----------\n",
      "Epoch 8/50\n",
      "TRAIN Loss: 0.02 Acc: 89.38\n",
      "VAL Loss: 0.00 Acc: 93.35\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "trainedDensenetWts = train_model(modelDensenetWts, optimizerDensenetWts, criterion, num_epochs=50, early_stopping=early_stopDensenetWts)\n",
    "\n",
    "pathDensenetWts = os.path.join(\"saved_models\", \"densenet121_weights.pth\")\n",
    "torch.save(trainedDensenetWts.state_dict(), pathDensenetWts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDensenet = models.densenet121()\n",
    "num_ftrs = modelDensenet.classifier.in_features\n",
    "\n",
    "for param in modelDensenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelDensenet.classifier = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "optimizerDensenet = optim.Adam(modelDensenet.classifier.parameters(), lr=0.001)\n",
    "\n",
    "early_stopDensenet = EarlyStopping(patience=7, delta=0.01)\n",
    "modelDensenet = modelDensenet.to(device)\n",
    "trainedDensenet = train_model(modelDensenet, optimizerDensenet, criterion, num_epochs=50, early_stopping=early_stopDensenet)\n",
    "\n",
    "pathDensenet = os.path.join(\"saved_models\", \"densenet121.pth\")\n",
    "torch.save(trainedDensenet.state_dict(), pathDensenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad6656",
   "metadata": {},
   "source": [
    "### Efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7093342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /Users/vky/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/50\n",
      "TRAIN Loss: 0.05 Acc: 80.87\n",
      "VAL Loss: 0.04 Acc: 77.24\n",
      "----------\n",
      "Epoch 2/50\n",
      "TRAIN Loss: 0.04 Acc: 83.84\n",
      "VAL Loss: 0.03 Acc: 85.29\n",
      "----------\n",
      "Epoch 3/50\n",
      "TRAIN Loss: 0.03 Acc: 83.34\n",
      "VAL Loss: 0.03 Acc: 86.45\n",
      "----------\n",
      "Epoch 4/50\n",
      "TRAIN Loss: 0.03 Acc: 90.53\n",
      "VAL Loss: 0.01 Acc: 92.46\n",
      "----------\n",
      "Epoch 5/50\n",
      "TRAIN Loss: 0.04 Acc: 85.39\n",
      "VAL Loss: 0.01 Acc: 96.29\n",
      "----------\n",
      "Epoch 6/50\n",
      "TRAIN Loss: 0.02 Acc: 91.18\n",
      "VAL Loss: 0.03 Acc: 88.75\n",
      "----------\n",
      "Epoch 7/50\n",
      "TRAIN Loss: 0.03 Acc: 87.90\n",
      "VAL Loss: 0.03 Acc: 77.75\n",
      "----------\n",
      "Epoch 8/50\n",
      "TRAIN Loss: 0.04 Acc: 82.30\n",
      "VAL Loss: 0.03 Acc: 86.83\n",
      "----------\n",
      "Epoch 9/50\n",
      "TRAIN Loss: 0.02 Acc: 83.84\n",
      "VAL Loss: 0.05 Acc: 65.09\n",
      "----------\n",
      "Epoch 10/50\n",
      "TRAIN Loss: 0.04 Acc: 80.10\n",
      "VAL Loss: 0.04 Acc: 81.59\n",
      "----------\n",
      "Epoch 11/50\n",
      "TRAIN Loss: 0.03 Acc: 81.42\n",
      "VAL Loss: 0.00 Acc: 93.48\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "modelEfficientWts = models.efficientnet_b0(weights= models.EfficientNet_B0_Weights.DEFAULT)\n",
    "num_ftrs = modelEfficientWts.classifier[1].in_features\n",
    "\n",
    "for param in modelEfficientWts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelEfficientWts.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "optimizerEfficientWts = optim.Adam(modelEfficientWts.classifier.parameters(), lr=0.001)\n",
    "\n",
    "early_stopEfficientWts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelEfficientWts = modelEfficientWts.to(device)\n",
    "\n",
    "trainedEfficientWts = train_model(modelEfficientWts, optimizerEfficientWts, criterion, num_epochs=50, early_stopping=early_stopEfficientWts)\n",
    "\n",
    "pathEfficientWts = os.path.join(\"saved_models\", \"efficientnet_b0_weights.pth\")\n",
    "torch.save(trainedEfficientWts.state_dict(), pathEfficientWts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3aba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/50\n",
      "TRAIN Loss: 0.07 Acc: 85.51\n",
      "VAL Loss: 0.03 Acc: 77.75\n",
      "----------\n",
      "Epoch 2/50\n"
     ]
    }
   ],
   "source": [
    "modelEfficient = models.efficientnet_b0()\n",
    "num_ftrs = modelEfficient.classifier[1].in_features\n",
    "\n",
    "for param in modelEfficient.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "modelEfficient.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "optimizerEfficient = optim.Adam(modelEfficient.classifier.parameters(), lr=0.001)\n",
    "\n",
    "early_stopEfficient = EarlyStopping(patience=7, delta=0.01)\n",
    "modelEfficient = modelEfficient.to(device)\n",
    "\n",
    "trainedEfficient = train_model(modelEfficient, optimizerEfficient, criterion, num_epochs=50, early_stopping=early_stopEfficient)\n",
    "\n",
    "pathEfficient = os.path.join(\"saved_models\", \"efficientnet_b0.pth\")\n",
    "torch.save(trainedEfficient.state_dict(), pathEfficient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
