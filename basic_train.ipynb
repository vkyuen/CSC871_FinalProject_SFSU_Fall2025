{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472bd647",
   "metadata": {},
   "source": [
    "# Creating and training models\n",
    "This file/notebook will create and train different models to see how different models will act.  Once the model has been trained, it will save the models to a folder for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_module import get_data_loaders\n",
    "import os\n",
    "\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fae29",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b530b2cf",
   "metadata": {},
   "source": [
    "## Loading data loaders\n",
    "Putting the loaders in a dictionary.  Since this file focuses on the models, I really only need the training and validation sets, but since all three loaders are given, it wouldn't hurt to add it to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e3c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders(batch_size=32)\n",
    "dataloaders = {\"TRAIN\": train_loader, \"VAL\": val_loader, \"TEST\": test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec03560",
   "metadata": {},
   "source": [
    "## Define a training function\n",
    "Followed a tutorial that trains and validates the model at each epoch. With each training, the model, optimizer, criterion, number of epochs and the early stopping critera can be set. \n",
    "\n",
    "At the end of each epoch, the statistics is printed to the console, before checking to see if the stopping critera has been met, and if the current model the is being tested is the best model.  If it is, then it is saved to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4554e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, num_epochs=50, early_stopping=None):\n",
    "    model.train()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        \n",
    "        for phase in [\"TRAIN\", \"VAL\"]:\n",
    "            if phase == \"TRAIN\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            # running_accuracy = 0.0\n",
    "            running_correct = 0\n",
    "            running_total = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == \"TRAIN\"):\n",
    "                    outputs = model(inputs)  # Shape: (batch_size, 1), dtype: float\n",
    "                    loss = criterion(outputs, labels)  # âœ… Convert labels to float\n",
    "                    prediction = torch.sigmoid(outputs).round().long()  # For accuracy calculation\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                if phase == \"TRAIN\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # running_accuracy += torch.sum(prediction == labels)\n",
    "                running_total += labels.size(0)\n",
    "                running_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / running_total\n",
    "            # epoch_acc = running_accuracy.double() / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = (running_correct/running_total) * 100\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.2f} Acc: {epoch_acc:.2f}')\n",
    "\n",
    "            # Early stopping\n",
    "            if phase == \"VAL\":\n",
    "                early_stopping(epoch_loss, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    return model\n",
    "\n",
    "            # Save the best model\n",
    "            if phase == \"VAL\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:.2f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad472a0f",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "This method checks to make sure the training stops in time to prevent overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546aec0",
   "metadata": {},
   "source": [
    "## Generate the different models\n",
    "Create instances of the different model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41eac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fbe42",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 56 * 56, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)  # Binary classification\n",
    "    )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b80a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN = cnn_model().to(device)\n",
    "optimizerCNN = optim.SGD(cnn_model().parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopCNN = EarlyStopping(patience=7, delta=0.01)\n",
    "modelCNN = modelCNN.to(device)\n",
    "\n",
    "trainedCNN = train_model(modelCNN, optimizerCNN, criterion, early_stopping=early_stopCNN)\n",
    "pathCNN = os.path.join(\"saved_models\", \"cnn.pth\")\n",
    "\n",
    "checkpointCNN = {'model_state_dict': trainedCNN.state_dict(),\n",
    "                 'optimizer_state_dict': optimizerCNN.state_dict()}\n",
    "torch.save(checkpointCNN, pathCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fe729f",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d01a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/50\n",
      "TRAIN Loss: 1.03 Acc: 77.65\n",
      "VAL Loss: 0.29 Acc: 92.97\n",
      "----------\n",
      "Epoch 2/50\n",
      "TRAIN Loss: 0.42 Acc: 82.84\n",
      "VAL Loss: 0.23 Acc: 88.24\n",
      "----------\n",
      "Epoch 3/50\n"
     ]
    }
   ],
   "source": [
    "modelResNet18Wts = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "optimizerResNet18Wts = optim.SGD(modelResNet18Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet18Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet18Wts = modelResNet18Wts.to(device)\n",
    "\n",
    "trainedResNet18Wts = train_model(modelResNet18Wts, optimizerResNet18Wts, criterion, early_stopping=early_stopResNet18Wts)\n",
    "\n",
    "pathResNet18Wts = os.path.join(\"saved_models\", \"resnet18_weights.pth\")\n",
    "\n",
    "checkpointResNet18Wts = {'model_state_dict': trainedResNet18Wts.state_dict(),\n",
    "                         'optimizer_state_dict': optimizerResNet18Wts.state_dict()}\n",
    "\n",
    "torch.save(checkpointResNet18Wts, pathResNet18Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet18 = models.resnet18()\n",
    "\n",
    "optimizerResNet18 = optim.SGD(modelResNet18.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet18 = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet18 = modelResNet18.to(device)\n",
    "\n",
    "trainedResNet18 = train_model(modelResNet18, optimizerResNet18, criterion, early_stopping=early_stopResNet18)\n",
    "\n",
    "pathResNet18 = os.path.join(\"saved_models\", \"resnet18.pth\")\n",
    "\n",
    "checkpointResNet18 = {'model_state_dict': trainedResNet18.state_dict(),\n",
    "                      'optimizer_state_dict': optimizerResNet18.state_dict()}\n",
    "\n",
    "torch.save(checkpointResNet18, pathResNet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383843c9",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0172662",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet50Wts = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "optimizerResNet50Wts = optim.SGD(modelResNet50Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet50Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet50Wts = modelResNet50Wts.to(device)\n",
    "\n",
    "trainedResNet50Wts = train_model(modelResNet50Wts, optimizerResNet50Wts, criterion, early_stopping=early_stopResNet50Wts)\n",
    "\n",
    "pathResNet50Wts = os.path.join(\"saved_models\", \"resnet50_weights.pth\")\n",
    "torch.save(trainedResNet50Wts.state_dict(), pathResNet50Wts)\n",
    "\n",
    "checkpointResNet50Wts = {'model_state_dict': trainedResNet50Wts.state_dict(),\n",
    "                         'optimizer_state_dict': optimizerResNet50Wts.state_dict()}\n",
    "\n",
    "torch.save(checkpointResNet50Wts, pathResNet50Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelResNet50 = models.resnet50()\n",
    "\n",
    "optimizerResNet50 = optim.SGD(modelResNet50.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopResNet50 = EarlyStopping(patience=7, delta=0.01)\n",
    "modelResNet50 = modelResNet50.to(device)\n",
    "\n",
    "trainedResNet50 = train_model(modelResNet50, optimizerResNet50, criterion, early_stopping=early_stopResNet50)\n",
    "\n",
    "pathResNet50 = os.path.join(\"saved_models\", \"resnet50.pth\")\n",
    "\n",
    "checkpointResNet50 = {'model_state_dict': trainedResNet50.state_dict(),\n",
    "                      'optimizer_state_dict': optimizerResNet50.state_dict()}\n",
    "\n",
    "torch.save(checkpointResNet50, pathResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5807f",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f26f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG16Wts = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "\n",
    "optimizerVGG16Wts = optim.SGD(modelVGG16Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopVGG16Wts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelVGG16Wts = modelVGG16Wts.to(device)\n",
    "\n",
    "trainedVGG16Wts = train_model(modelVGG16Wts, optimizerVGG16Wts, criterion, early_stopping=early_stopVGG16Wts)\n",
    "\n",
    "pathVGG16Wts = os.path.join(\"saved_models\", \"vgg16_weights.pth\")\n",
    "\n",
    "checkpointVGG16Wts = {'model_state_dict': trainedVGG16Wts.state_dict(),\n",
    "                      'optimizer_state_dict': optimizerVGG16Wts.state_dict()}\n",
    "\n",
    "torch.save(checkpointVGG16Wts, pathVGG16Wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVGG16 = models.vgg16()\n",
    "\n",
    "optimizerVGG16 = optim.SGD(modelVGG16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopVGG16 = EarlyStopping(patience=7, delta=0.01)\n",
    "modelVGG16 = modelVGG16.to(device)\n",
    "\n",
    "trainedVGG16 = train_model(modelVGG16, optimizerVGG16, criterion, early_stopping=early_stopVGG16)\n",
    "\n",
    "pathVGG16 = os.path.join(\"saved_models\", \"vgg16.pth\")\n",
    "\n",
    "checkpointVGG16 = {'model_state_dict': trainedVGG16.state_dict(),\n",
    "                   'optimizer_state_dict': optimizerVGG16.state_dict()}\n",
    "torch.save(checkpointVGG16, pathVGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd0aa4d",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDensenetWts = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "\n",
    "optimizerDensenetWts = optim.SGD(modelDensenetWts.classifier.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopDensenetWts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelDensenetWts = modelDensenetWts.to(device)\n",
    "\n",
    "trainedDensenetWts = train_model(modelDensenetWts, optimizerDensenetWts, criterion, early_stopping=early_stopDensenetWts)\n",
    "\n",
    "pathDensenetWts = os.path.join(\"saved_models\", \"densenet121_weights.pth\")\n",
    "\n",
    "chckpointDensenetWts = {'model_state_dict': trainedDensenetWts.state_dict(),\n",
    "                        'optimizer_state_dict': optimizerDensenetWts.state_dict()}\n",
    "torch.save(chckpointDensenetWts, pathDensenetWts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDensenet = models.densenet121()\n",
    "\n",
    "optimizerDensenet = optim.SGD(modelDensenet.classifier.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopDensenet = EarlyStopping(patience=7, delta=0.01)\n",
    "modelDensenet = modelDensenet.to(device)\n",
    "trainedDensenet = train_model(modelDensenet, optimizerDensenet, criterion, early_stopping=early_stopDensenet)\n",
    "\n",
    "pathDensenet = os.path.join(\"saved_models\", \"densenet121.pth\")\n",
    "\n",
    "checkpointDensenet = {'model_state_dict': trainedDensenet.state_dict(),\n",
    "                      'optimizer_state_dict': optimizerDensenet.state_dict()}\n",
    "torch.save(checkpointDensenet, pathDensenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad6656",
   "metadata": {},
   "source": [
    "### Efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7093342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEfficientWts = models.efficientnet_b0(weights= models.EfficientNet_B0_Weights.DEFAULT)\n",
    "\n",
    "optimizerEfficientWts = optim.SGD(modelEfficientWts.classifier.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopEfficientWts = EarlyStopping(patience=7, delta=0.01)\n",
    "modelEfficientWts = modelEfficientWts.to(device)\n",
    "\n",
    "trainedEfficientWts = train_model(modelEfficientWts, optimizerEfficientWts, criterion, early_stopping=early_stopEfficientWts)\n",
    "\n",
    "pathEfficientWts = os.path.join(\"saved_models\", \"efficientnet_b0_weights.pth\")\n",
    "\n",
    "checkpointEfficientWts = {'model_state_dict': trainedEfficientWts.state_dict(),\n",
    "                          'optimizer_state_dict': optimizerEfficientWts.state_dict()}\n",
    "torch.save(checkpointEfficientWts, pathEfficientWts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3aba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEfficient = models.efficientnet_b0()\n",
    "\n",
    "optimizerEfficient = optim.SGD(modelEfficient.classifier.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "early_stopEfficient = EarlyStopping(patience=7, delta=0.01)\n",
    "modelEfficient = modelEfficient.to(device)\n",
    "\n",
    "trainedEfficient = train_model(modelEfficient, optimizerEfficient, criterion, early_stopping=early_stopEfficient)\n",
    "\n",
    "pathEfficient = os.path.join(\"saved_models\", \"efficientnet_b0.pth\")\n",
    "\n",
    "checkpointEfficient = {'model_state_dict': trainedEfficient.state_dict(),\n",
    "                       'optimizer_state_dict': optimizerEfficient.state_dict()}\n",
    "torch.save(checkpointEfficient, pathEfficient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
