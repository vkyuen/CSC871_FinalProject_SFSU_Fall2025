{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472bd647",
   "metadata": {},
   "source": [
    "# Creating models and saving to an array \n",
    "Assuming the models are pre-set, and there is a folder named saved_models that holds all the models. Since the saved state dictionary were processed using GPU, speed up, the device should \n",
    "\n",
    "The get method will return arras wtith the model name, the models, and the optimizer.  The criterion is not included because the same one is used across all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fbe42",
   "metadata": {},
   "source": [
    "### CNN\n",
    "This is the only model that we have to create, all the other models are pre-trained in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 56 * 56, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)  # Binary classification\n",
    "    )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95bcc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isTroubleshoot = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9a41f",
   "metadata": {},
   "source": [
    "## Load models\n",
    "This class will take in the path to the folder that has all the models. Assuming all the file names are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loadModels:\n",
    "    # modelNames = ['cnn', 'resnet18_weights', 'resnet18', 'resnet50_weights', 'resnet50', \n",
    "    #               'vgg16_weights', 'vgg16', 'densenet121_weights', 'densenet121', \n",
    "    #               'efficientnet_b0_weights', 'efficientnet_b0']\n",
    "    modelNames = ['cnn', 'resnet18_weights', 'resnet18', 'resnet50_weights', 'resnet50', \n",
    "                  'densenet121_weights', 'densenet121', 'efficientnet_b0_weights', \n",
    "                  'efficientnet_b0']\n",
    "    models = []\n",
    "\n",
    "    path = \"\"\n",
    "    device = \"\"\n",
    "    def __init__(self, path, device):\n",
    "        self.path = path\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def get_files_in_folder(self, folder_path):\n",
    "        # Check if the provided path is a valid directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for entry in os.listdir(folder_path):\n",
    "                full_path = os.path.join(folder_path, entry)\n",
    "                # Check if the entry is a file\n",
    "                if os.path.isfile(full_path):\n",
    "                    entry = self.remove_file_extension(entry)\n",
    "                    self.modelNames.append(entry)\n",
    "        else:\n",
    "            print(f\"Error: '{folder_path}' is not a valid directory.\")\n",
    "    \n",
    "    def remove_file_extension(self, filepath):\n",
    "        filename_without_extension, _ = os.path.splitext(filepath)\n",
    "        return filename_without_extension\n",
    "    \n",
    "    def load_models(self):\n",
    "        # Load CNN model\n",
    "        modelCNN = cnn_model().to(self.device)\n",
    "\n",
    "        checkpointCNN = torch.load(os.path.join(self.path, \"cnn.pth\"), map_location=self.device)\n",
    "        modelCNN.load_state_dict(checkpointCNN['model_state_dict'])\n",
    "        self.models.append(modelCNN)\n",
    "        \n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded CNN model.\")\n",
    "        \n",
    "        # Load ResNet18 with weights\n",
    "        modelResNet18Wts = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelResNet18Wts.fc.in_features\n",
    "\n",
    "        for param in modelResNet18Wts.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet18Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "        \n",
    "        checkpointResNet18Wts = torch.load(os.path.join(self.path, \"resnet18_weights.pth\"), map_location=self.device)\n",
    "        modelResNet18Wts.load_state_dict(checkpointResNet18Wts['model_state_dict'])\n",
    "        self.models.append(modelResNet18Wts)\n",
    "        \n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded ResNet18 with weights model.\")\n",
    "\n",
    "        # Load ResNet18 without weights\n",
    "        modelResNet18 = models.resnet18().to(self.device)\n",
    "        num_ftrs = modelResNet18.fc.in_features\n",
    "\n",
    "        for param in modelResNet18.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet18.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "\n",
    "        checkpointResNet18 = torch.load(os.path.join(self.path, \"resnet18.pth\"), map_location=self.device)\n",
    "        modelResNet18.load_state_dict(checkpointResNet18['model_state_dict'])\n",
    "        self.models.append(modelResNet18)\n",
    "        \n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded ResNet18 without weights model.\")\n",
    "\n",
    "        # Load ResNet50 with weights\n",
    "        modelResNet50Wts = models.resnet50(weights=models.ResNet50_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelResNet50Wts.fc.in_features\n",
    "\n",
    "        for param in modelResNet50Wts.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet50Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "\n",
    "        checkpointResNet50Wts = torch.load(os.path.join(self.path, \"resnet50_weights.pth\"), map_location=self.device)\n",
    "        modelResNet50Wts.load_state_dict(checkpointResNet50Wts['model_state_dict'])\n",
    "        self.models.append(modelResNet50Wts)\n",
    "\n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded ResNet50 with weights model.\")\n",
    "\n",
    "        # Load ResNet50 without weights\n",
    "        modelResNet50 = models.resnet50().to(self.device)\n",
    "        num_ftrs = modelResNet50.fc.in_features\n",
    "\n",
    "        for param in modelResNet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet50.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "\n",
    "        checkpointResNet50 = torch.load(os.path.join(self.path, \"resnet50.pth\"), map_location=self.device)\n",
    "        modelResNet50.load_state_dict(checkpointResNet50['model_state_dict'])\n",
    "        self.models.append(modelResNet50)\n",
    "\n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded ResNet50 without weights model.\")\n",
    "\n",
    "        # Load VGG16 with weights\n",
    "        # modelVGG16Wts = models.vgg16(weights=models.VGG16_Weights.DEFAULT).to(self.device)\n",
    "\n",
    "        # for param in modelVGG16Wts.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # num_features = 4096\n",
    "        # features = list(modelVGG16Wts.classifier.children())[:-1]\n",
    "        # features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "        # modelVGG16Wts.classifier = nn.Sequential(*features)\n",
    "\n",
    "        # checkpointVGG16Wts = torch.load(os.path.join(self.path, \"vgg16_weights.pth\"), map_location=self.device)\n",
    "        # modelVGG16Wts.load_state_dict(checkpointVGG16Wts['model_state_dict'])\n",
    "        # self.models.append(modelVGG16Wts)\n",
    "\n",
    "        # if(isTroubleshoot):\n",
    "        #     print(\"Loaded VGG16 with weights model.\")\n",
    "\n",
    "        # # Load VGG16 without weights\n",
    "        # modelVGG16 = models.vgg16().to(self.device)\n",
    "        \n",
    "        # for param in modelVGG16.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # num_features = modelVGG16.classifier[6].in_features\n",
    "        # features = list(modelVGG16.classifier.children())[:-1]\n",
    "        # features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "        # modelVGG16.classifier = nn.Sequential(*features)\n",
    "        \n",
    "        # checkpointVGG16 = torch.load(os.path.join(self.path, \"vgg16.pth\"), map_location=self.device)\n",
    "        # modelVGG16.load_state_dict(checkpointVGG16['model_state_dict'])\n",
    "        # self.models.append(modelVGG16)\n",
    "\n",
    "        # if(isTroubleshoot):\n",
    "        #     print(\"Loaded VGG16 without weights model.\")\n",
    "\n",
    "        # Load DenseNet121 with weights\n",
    "        modelDensenetWts = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelDensenetWts.classifier.in_features\n",
    "\n",
    "        for param in modelDensenetWts.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        modelDensenetWts.classifier = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "\n",
    "        checkpointDensenetWts = torch.load(os.path.join(self.path, \"densenet121_weights.pth\"), map_location=self.device)\n",
    "        modelDensenetWts.load_state_dict(checkpointDensenetWts['model_state_dict'])\n",
    "        self.models.append(modelDensenetWts)\n",
    "\n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded DenseNet121 with weights model.\")\n",
    "\n",
    "        # Load DenseNet121 without weights\n",
    "        modelDensenet = models.densenet121().to(self.device)\n",
    "        num_ftrs = modelDensenet.classifier.in_features\n",
    "\n",
    "        for param in modelDensenet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        modelDensenet.classifier = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "\n",
    "        checkpointDensenet = torch.load(os.path.join(self.path, \"densenet121.pth\"), map_location=self.device)\n",
    "        modelDensenet.load_state_dict(checkpointDensenet['model_state_dict'])\n",
    "        self.models.append(modelDensenet)\n",
    "\n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded DenseNet121 without weights model.\")\n",
    "\n",
    "        # Load EfficientNet_B0 with weights\n",
    "        modelEfficientNetWts = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelEfficientNetWts.classifier[1].in_features\n",
    "\n",
    "        for param in modelEfficientNetWts.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        modelEfficientNetWts.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "\n",
    "        checkpointEfficientNetWts = torch.load(os.path.join(self.path, \"efficientnet_b0_weights.pth\"), map_location=self.device)\n",
    "        modelEfficientNetWts.load_state_dict(checkpointEfficientNetWts['model_state_dict'])\n",
    "        self.models.append(modelEfficientNetWts)\n",
    "\n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded EfficientNet_B0 with weights model.\")\n",
    "\n",
    "        # Load EfficientNet_B0 without weights\n",
    "        modelEfficientNet = models.efficientnet_b0().to(self.device)\n",
    "        num_ftrs = modelEfficientNet.classifier[1].in_features\n",
    "\n",
    "        for param in modelEfficientNet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        modelEfficientNet.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "\n",
    "        checkpointEfficientNet = torch.load(os.path.join(self.path, \"efficientnet_b0.pth\"), map_location=self.device)\n",
    "        modelEfficientNet.load_state_dict(checkpointEfficientNet['model_state_dict'])\n",
    "        self.models.append(modelEfficientNet)\n",
    "\n",
    "        if(isTroubleshoot):\n",
    "            print(\"Loaded EfficientNet_B0 without weights model.\")\n",
    "\n",
    "    def get_models(self):\n",
    "        return self.models\n",
    "    \n",
    "    def get_models_names(self):\n",
    "        return self.modelNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09deb372",
   "metadata": {},
   "source": [
    "# Running the model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loadAllModels = loadModels(os.path.join(\"saved_models\"), torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bda9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_names = []\n",
    "loaded_models = []\n",
    "\n",
    "loaded_models = loadAllModels.load_models()\n",
    "loaded_model_names = loadAllModels.modelNames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
